![img](res/other/异世界蕾姆_1.png)

[TOC]

***

# 基础概念

> [Python进程、线程和协程实战指归](https://zhuanlan.zhihu.com/p/335309471)
>
> [异步编程基本概念](https://blog.csdn.net/lu8000/article/details/45025987)
>
> 

## 进程、线程和协程

> 多进程适合在CPU 密集型操作(CPU操作指令比较多，如科学计算，位数多的浮点运算)
>
> 多线程适合在IO 密集型操作(读写数据操作较多的，比如爬虫)
>
> * 线程是并发，进程是并行；进程之间相互独立，是系统分配资源的最小单位，同一个进程中的所有线程共享资源，进程拥有自己的内存空间，所以进程间数据不共享，开销大。
>
> * 线程：调度执行的最小单位，也叫执行路径，不能独立存在，依赖进程的存在而存在，一个进程至少有一个线程，叫主线程，多个线程共享内存（数据共享和全局变量），因此提升程序的运行效率。
>
> * 协程：用户态的轻量级线程，调度有用户控制，拥有自己的寄存器上下文和栈，切换基本没有内核切换的开销，切换灵活。

### 进程

> **进程最大优势是可以充分例用计算资源**
>
> 使用进程处理**计算密集型**任务：因为不同的进程可以运行的不同CPU的不同的核上。假如一台计算机的CPU共有16核，则可以启动16个或更多个进程来并行处理任务
> 使用单个线程或两个线程的时候，耗时大约30+秒，改用两个进程后，耗时17.786秒，差不多快了一倍。如果使用4个进程（前提是运行的代码的计算机至少有4个CPU核）的话，速度还能提高一倍。对于计算密集型的任务，使用多进程并行处理是**有效的提速手段**。通常，**进程数量选择CPU核数的整倍数**。
> **线程间通信**可以使用**队列、互斥锁、信号量、事件和条件等多种同步方式**，同样的，这些手段也可以应用在进程间。此外，multiprocessing 模块还提供了管道和共享内存等进程间通信的手段。
>
> **进程池**：使用多进程并行处理任务时，处理效率和进程数量并不总是成正比。当进程数量超过一定限度后，完成任务所需时间反而会延长。进程池提供了一个保持合理进程数量的方案，但合理进程数量需要根据硬件状况及运行状况来确定，通常设置为 CPU 的核数。
> multiprocessing.Pool(n) 可创建 n 个进程的进程池供用户调用。如果进程池任务不满，则新的进程请求会被立即执行；如果进程池任务已满，则新的请求将等待至有可用进程时才被执行。
>
> **向进程池提交任务有以下两种方式**：
>
> * apply_async(func[, args[, kwds[, callback]]]) ：非阻塞式提交。即使进程池已满，也会接受新的任务，不会阻塞主进程。新任务将处于等待状态
> * apply(func[, args[, kwds]]) ：阻塞式提交。若进程池已满，则主进程阻塞，直至有空闲进程可以使用

### 线程

> **线程的最大意义在于并行**
> 使用线程处理**IO密集型**任务：对于IO密集型（本例仅测试网络IO，没有磁盘IO）的任务，适量的线程可以在一定程度上提高处理速度。随着线程数量的增加，速度的提升不再明显。
> 使用线程处理**计算密集型**任务
> 对一张千万级像素的照片做低端增强，借助于NumPy的广播和矢量化计算，耗时0.38秒钟；单线程逐像素处理的话，耗时相当于NumPy的100倍；启用多线程的话，速度不仅没有加快，反倒是比单线程更慢。
>
> 这说明，对于**计算密集型**的任务来说，**多线程并不能提高处理速度**，相反，因为要创建和管理线程，处理速度会更慢一些。
> **线程池**：尽管多线程可以并行处理多个任务，但开启线程不仅花费时间，也需要占用系统资源。因此，线程数量不是越多越快，而是要保持在合理的水平上。线程池可以让我们用固定数量的线程完成比线程数量多得多的任务



### 协程

#### 概念

> 线程常用于多任务并行。对于可以切分的IO密集型任务，将切分的每一小块任务分配给一个线程，可以显著提高处理速度。而协程，无论有多少个，都被**限定在一个线程内执行**，因此，协程又被称为**微线程**。
>
> * 从**宏观**上看，**线程**任务和**协程**任务都是**并行**的
> * 从**微观**上看，**线程**任务是分时**切片轮流执行**的，这种切换是系统自动完成的，无需程序员干预；而**协程**则是根据任务特点，在任务阻塞时将**控制权**交给其他协程，这个权力**交接的时机和位置**，由**程序员指定**。
> * 参与协程管理的每一个任务，必须存在阻塞的可能，且阻塞条件会被其它任务破坏，从而得以在阻塞解除后继续执行。
>
> 尽管协程**难以驾驭**，但是由于是在**一个线程内**运行，**免除**了线程或进程的**切换开销**，因而协程的**运行效率高**，在特定场合下仍然被广泛使用。

#### 协程演进史

> 1. Py2时代，Python并不支持协程，仅可通过yield实现部分的协程功能
>
> 2. 另外可以通过**gevent等第三方库**实现协程，gevent最好玩的，莫过于monkey_patch(猴子补丁)
> 3. Py3.4开始，Python内置**asyncio标准库**，正式**原生支持协程**。asyncio的异步操作，需要在协程中通过yield from完成，协程函数则需要使用@asyncio.coroutine装饰器
> 4. 为了更贴近人类思维，Py3.5引入了**新的语法async和await**，可以让协程的代码稍微易懂一点点
>
> 本质上，async就是@asyncio.coroutine，替换为await就是yield from，换个马甲，看起来就顺眼多了。

### 多线程和协程关系

#### 使用场景

>如果是 **I/O 密集型**，且 **I/O 请求比较耗时**的话，使用**协程**
>
>如果是 **I/O 密集型**，且 **I/O 请求比较快**的话，使用**多线程**
>
>如果是 **计算 密集型**，考虑可以使用多核 CPU，使用**多进程**

#### 异同点比较

>**共同点**：都是并发操作，多线程同一时间点只能有一个线程在执行，协程同一时间点只能有一个任务在执行；
>
>**不同点**：多线程，是在I/O阻塞时通过切换线程来达到并发的效果，在什么情况下做线程切换是由操作系统来决定的，开发者不用操心，但会造成竞争条件 (race condition) 
>
>* 协程，只有一个线程，在I/O阻塞时通过在线程内切换任务来达到并发的效果，在什么情况下做任务切换是开发者决定的，不会有竞争条件 (race condition) 的情况；
>
>* 多线程的线程切换比协程的任务切换开销更大；
>
>* 对于开发者而言，多线程并发的代码比协程并发的更容易书写，一般情况下协程并发的处理效率比多线程并发更高。
>
>**ps**：[对第一点和第二点补充](https://www.zhihu.com/question/440212832/answer/1687877241)
>
>* 对于io阻塞的操作，协程相较于线程，能更精确的获取（或者释放）对资源的控制权
>* 这是因为用户层相较于语言层，用户层能更好的感知特定操作的时机
>* 对于非io阻塞的操作，线程相较于协程，能更公平的分配对资源的控制权
>* 这是因为语言层相较于用户层，语言层能更好的感知到多个线程的运行状态，并在掌握更多信息的前提下（线程运行的字节码和时长），进行更加合理的GIL的获取和释放

## 阻塞和非阻塞

###  阻塞

> * 程序未得到所需计算资源时被挂起的状态
> * 程序在等待某个操作完成期间，自身无法继续干别的事情，称程序在该操作上是阻塞的
> * 常见的阻塞形式有：网络I/O阻塞、磁盘I/O阻塞、用户输入阻塞等
>
> 阻塞是无处不在的，包括CPU切换上下文时，所有的进程都无法真正干事情，它们也会被阻塞（如果是多核CPU则正在执行上下文切换操作的核不可被利用）

### 非阻塞

> * 程序在等待某操作过程中，自身不被阻塞，可以继续运行干别的事情，则称该程序在该操作上是非阻塞的
> * 非阻塞并**不是**在任何程序级别、任何情况下都可以存在的
> * 仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态
>
> 非阻塞的存在是因为阻塞存在，正因为某个操作阻塞导致的耗时与效率低下，我们才要把它变成非阻塞的

## 异步和同步

### 同步

> - 不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以**协调一致**，称这些程序单元是同步执行的
> - 例如购物系统中更新商品库存，需要用“行锁”作为通信信号，让不同的更新请求强制排队顺序执行，那更新库存的操作是同步的
> - 简言之，**同步意味着有序**

### 异步

> - 为完成某个任务，不同程序单元之间**过程中无需通信协调**，也能完成任务的方式
> - 不相关的程序单元之间可以是异步的
> - 例如，爬虫下载网页。调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是无关的，也无需相互通知协调。这些异步操作的完成时刻并不确定
> - 简言之，**异步意味着无序**

## 并行和并发

### 并发(多线程)

>**任务特点**：IO密集型任务：任务包含频繁的、持续的网络IO和磁盘IO
>
>单个CPU（也可以多个CPU）将多个线程中的每个线程（多个进程中的每个进程）按时间分为一个一个的时间片，每一个时刻只执行某个线程（进程）的时间片，时间片过期后转而执行下一个线程（进程）的时间片
>
>- 并发描述的是程序的组织结构。指程序要被设计成多个可独立执行的子任务。
>- 以利用有限的计算机资源使多个任务可以被实时或近实时执行为目的。
>
>并发提供了一种程序组织结构方式，让问题的解决方案可以并行执行，
>
>**注：并发宏观上看起来像是并行但是微观上并不能做到并行**

### 并行(多进程)

>**任务特点**：计算密集型任务：任务包含大量计算，CPU占用率高
>
>当有多个CPU或者是多核CPU时才有可能实现并行，并行就是多个线程或者多个进程同时运行
>
>- 并行描述的是程序的执行状态。指多个任务同时被执行。
>- 以利用富余计算资源（多核CPU）加速完成多个任务为目的。

## 概念总结

> - **并行**是为了利用多核加速多任务完成的进度
> - **并发**是为了让独立的子任务都有机会被尽快执行，但不一定能加速整体进度
> - **非阻塞**是为了提高程序整体执行效率
> - **异步**是高效地组织非阻塞任务的方式
>
> 要支持并发，必须拆分为多任务，不同任务相对而言才有阻塞/非阻塞、同步/异步
>
> 所以，并发、异步、非阻塞三个词总是如影随形



# 异步编程

## 协程多种实现方式

> [python协程的多种实现方式](https://blog.csdn.net/wf134/article/details/78553181)

> 在Python中有多种方式可以实现协程，例如：
>
> - greenlet，是一个第三方模块，用于实现协程代码（Gevent协程就是基于greenlet实现）
> - yield，生成器，借助生成器的特点也可以实现协程代码
> - asyncio，在Python3.4中引入的模块用于编写协程代码
> - async & awiat，在Python3.5中引入的两个关键字，结合asyncio模块可以更方便的编写协程代码
>
> 关于协程有多种实现方式，目前主流使用是Python官方推荐的asyncio模块和async&await关键字的方式，例如：在tonado、sanic、fastapi、django3 中均已支持

## 任务类型

> * 计算密集型任务：任务包含大量计算，CPU占用率高
> * IO密集型任务：任务包含频繁的、持续的网络IO和磁盘IO
> * 混合型任务：既有计算也有IO

## 事件循环

> [python Event_loop(事件循环)](https://www.cnblogs.com/xiaozx/p/10639875.html)
>
> [Python 协程与事件循环](https://www.cnblogs.com/rgbit/p/10539520.html)



### 消息队列

> [rabbitmq和redis用作消息队列的区别](https://www.cnblogs.com/kangao/p/11156180.html)

##  asyncio 标准库 

### 新的概念

#### 协程装饰器

在 Python 3.4 中，asyncio 模块出现，此时创建协程函数须使用 asyncio.coroutine 装饰器标记。此前的包含 yield from 语句的函数既可以称作生成器函数也可以称作协程函数，为了突出协程的重要性，现在使用 asyncio.coroutine 装饰器的函数就是真正的协程函数了。

#### coroutine 协程

**协程对象**，使用 asyncio.coroutine 装饰器装饰的函数被称作协程函数，它的调用不会立即执行函数，而是返回一个协程对象，即协程函数的运行结果为协程对象，注意这里说的 “运行结果” 不是 return 值。协程对象需要包装成任务注入到事件循环，由事件循环调用。

#### task 任务

将协程对象作为参数创建任务，任务是对协程对象的进一步封装，其中包含任务的各种状态。

#### event_loop 事件循环

在上一节实验中介绍线程时，将多线程比喻为工厂里的多个车间，那么协程就是一个车间内的多台机器。在线程级程序中，一台机器开始工作，车间内的其它机器不能同时工作，需要等上一台机器停止，但其它车间内的机器可以同时启动，这样就可以显著提高工作效率。在协程程序中，一个车间内的不同机器可以同时运转，启动机器、暂停运转、延时启动、停止机器等操作都可以人为设置。

事件循环能够控制任务运行流程，也就是任务的调用方。

#### 协程入门例子

```python
In [50]: import time
In [51]: import asyncio
In [52]: def one():
    ...:     start = time.time()
    ...:     @asyncio.coroutine   # 1
    ...:     def do_some_work():  # 2
    ...:         print('Start coroutine')
    ...:         time.sleep(0.1)  # 3
    ...:         print('This is a coroutine')
    ...:
    ...:     loop = asyncio.get_event_loop()     # 4
    ...:     coroutine = do_some_work()          # 5
    ...:     loop.run_until_complete(coroutine)  # 6
    ...:
    ...:     end = time.time()
    ...:     print('运行耗时：{:.4f}'.format(end - start))  # 7
    ...:

In [53]: one()
Start coroutine
This is a coroutine
运行耗时：0.1062
```

> 代码说明：
>
> 1、使用协程装饰器创建协程函数
>
> 2、协程函数
>
> 3、模拟 IO 操作
>
> 4、创建事件循环。每个线程中只能有一个事件循环，get_event_loop 方法会获取当前已经存在的事件循环，如果当前线程中没有，新建一个
>
> 5、调用协程函数获取协程对象
>
> 6、将协程对象注入到事件循环，协程的运行由事件循环控制。事件循环的 run_until_complete 方法会阻塞运行，直到任务全部完成。协程对象作为 run_until_complete 方法的参数，loop 会自动将协程对象包装成任务来运行。后面我们会讲到多个任务注入事件循环的情况
>
> 7、打印程序运行耗时

#### 协程对象运行

协程对象不能直接运行，必须放入事件循环中或者由 yield from 语句调用。将协程对象注入事件循环的时候，其实是 run_until_complete 方法将协程包装成了一个任务（task）对象，任务对象保存了协程运行后的状态，用于未来获取协程的结果。

```python
In [56]: def two():
    ...:     start = time.time()
    ...:
    ...:     @asyncio.coroutine
    ...:     def do_some_work():
    ...:         print('Start coroutine')
    ...:         time.sleep(0.1)
    ...:         print('This is a coroutine')
    ...:
    ...:     loop = asyncio.get_event_loop()
    ...:     coroutine = do_some_work()
    ...:     task = loop.create_task(coroutine)  # 1
    ...:     print('task 是不是 asyncio.Task 的实例？', isinstance(task, asyncio.Task))  # 2
    ...:     print('Task state:', task._state)   # 3
    ...:     loop.run_until_complete(task)       # 4
    ...:     print('Task state:', task._state)
    ...:
    ...:     end = time.time()
    ...:     print('运行耗时：{:.4f}'.format(end - start))
    ...:

In [57]: two()
task 是不是 asyncio.Task 的实例？ True
Task state: PENDING
Start coroutine
This is a coroutine
Task state: FINISHED
运行耗时：0.1052
```

> 代码说明：
>
> 1、事件循环的 create_task 方法可以创建任务，另外 asyncio.ensure_future 方法也可以创建任务，参数须为协程对象
>
> 2、task 是 asyncio.Task 类的实例，为什么要使用协程对象创建任务？因为在这个过程中 asyncio.Task 做了一些工作，包括预激协程、协程运行中遇到某些异常时的处理
>
> 3、task 对象的 _state 属性保存当前任务的运行状态，任务的运行状态有 PENDING 和 FINISHED 两种
>
> 4、将任务注入事件循环，阻塞运行

> 在 Python 3.5 中新增了 async / await 关键字用来定义协程函数。这两个关键字是一个组合，其作用等同于 asyncio.coroutine 装饰器和 yield from 语句。此后协程与生成器就彻底泾渭分明了。



#### 绑定回调

有了 asyncio / await 关键字，我们继续学习 asyncio 模块的基本功能。

假如协程包含一个 IO 操作（这几乎是肯定的），等它处理完数据后，我们希望得到通知，以便下一步数据处理。这一需求可以通过向 future 对象中添加回调来实现。那么什么是 future 对象？task 对象就是 future 对象，我们可以这样认为，因为 asyncio.Task 是 asyncio.Future 的子类。也就是说，task 对象可以添加回调函数。回调函数的最后一个参数是 future 或 task 对象，通过该对象可以获取协程返回值。如果回调需要多个参数，可以通过偏函数导入。

简言之，一个任务完成后需要捎带运行的代码可以放到回调函数中。修改上一个程序如下：

```python
In [64]: def three():
    ...:     start = time.time()
    ...:
    ...:     # @asyncio.coroutine
    ...:     async def corowork():      # 1
    ...:         print('[corowork] Start coroutine')
    ...:         time.sleep(0.1)
    ...:         print('[corowork] This is a coroutine')
    ...:
    ...:     def callback(name, task):  # 2 
    ...:         print('[callback] Hello {}'.format(name))
    ...:         print('[callback] coroutine state: {}'.format(task._state))
    ...:
    ...:     loop = asyncio.get_event_loop()
    ...:     coroutine = corowork()
    ...:     task = loop.create_task(coroutine)
    ...:     task.add_done_callback(functools.partial(callback, 'Shiyanlou'))  # 3
    ...:     loop.run_until_complete(task)
    ...:
    ...:     end = time.time()
    ...:     print('运行耗时：{:.4f}'.format(end - start))
    ...:

In [65]: import functools

In [66]: three()
[corowork] Start coroutine
[corowork] This is a coroutine
[callback] Hello Shiyanlou
[callback] coroutine state: FINISHED
运行耗时：0.1051
```

> 代码说明：
>
> 1、使用 async 关键字替代 asyncio.coroutine 装饰器创建协程函数
>
> 2、回调函数，协程终止后需要顺便运行的代码写入这里，回调函数的参数有要求，最后一个位置参数须为 task 对象
>
> 3、task 对象的 add_done_callback 方法可以添加回调函数，注意参数必须是回调函数，这个方法不能传入回调函数的参数，这一点需要通过 functools 模块的 partial 方法解决，将回调函数和其参数 name 作为 partial 方法的参数，此方法的返回值就是偏函数，偏函数可作为 task.add_done_callback 方法的参数

#### 多任务

实际项目中，往往有多个协程创建多个任务对象，同时在一个 loop 里运行。为了把多个协程交给 loop，需要借助 asyncio.gather 方法。任务的 result 方法可以获得对应的协程函数的 return 值。

```python
In [67]: def four():
    ...:     start = time.time()
    ...:
    ...:     async def corowork(name, t):
    ...:         print('[corowork] Start coroutine', name)
    ...:         await asyncio.sleep(t)                  # 1
    ...:         print('[corowork] Stop coroutine', name)
    ...:         return 'Coroutine {} OK'.format(name)   # 2
    ...:
    ...:     loop = asyncio.get_event_loop()
    ...:     coroutine1 = corowork('ONE', 3)             # 3
    ...:     coroutine2 = corowork('TWO', 1)             # 3
    ...:     task1 = loop.create_task(coroutine1)        # 4
    ...:     task2 = loop.create_task(coroutine2)        # 4
    ...:     gather = asyncio.gather(task1, task2)       # 5
    ...:     loop.run_until_complete(gather)             # 6
    ...:     print('[task1] ', task1.result())           # 7
    ...:     print('[task2] ', task2.result())           # 7
    ...:
    ...:     end = time.time()
    ...:     print('运行耗时：{:.4f}'.format(end - start))

In [68]: four()
[corowork] Start coroutine ONE
[corowork] Start coroutine TWO
[corowork] Stop coroutine TWO
[corowork] Stop coroutine ONE
[task1]  Coroutine ONE OK
[task2]  Coroutine TWO OK
运行耗时：3.0070
```

> 代码说明：
>
> 1、await 关键字等同于 Python 3.4 中的 yield from 语句，后面接协程对象。asyncio.sleep 方法的返回值为协程对象，这一步为阻塞运行。asyncio.sleep 与 time.sleep 是不同的，前者阻塞当前协程，即 corowork 函数的运行，而 time.sleep 会阻塞整个线程，所以这里必须用前者，阻塞当前协程，CPU 可以在线程内的其它协程中执行
>
> 2、协程函数的 return 值可以在协程运行结束后保存到对应的 task 对象的 result 方法中
>
> 3、创建两个协程对象，在协程内部分别阻塞 3 秒和 1 秒
>
> 4、创建两个任务对象
>
> 5、将任务对象作为参数，asyncio.gather 方法创建任务收集器。注意，asyncio.gather 方法中参数的顺序决定了协程的启动顺序
>
> 6、将任务收集器作为参数传入事件循环的 run_until_complete 方法，阻塞运行，直到全部任务完成
>
> 7、任务结束后，事件循环停止，打印任务的 result 方法返回值，即协程函数的 return 值
>
> 到这一步，大家应该可以看得出，上面的代码已经是异步编程的结构了，在事件循环内部，两个协程是交替运行完成的。简单叙述一下程序协程部分的运行过程：
>
> -> 首先运行 task1
>
> -> 打印 [corowork] Start coroutine ONE
>
> -> 遇到 asyncio.sleep 阻塞
>
> -> 释放 CPU 转到 task2 中执行
>
> -> 打印 [corowork] Start coroutine TWO
>
> -> 再次遇到 asyncio.sleep 阻塞
>
> -> 这次没有其它协程可以运行了，只能等阻塞结束
>
> -> task2 的阻塞时间较短，阻塞 1 秒后先结束，打印 [corowork] Stop coroutine TWO
>
> -> 又过了 2 秒，阻塞 3 秒的 task1 也结束了阻塞，打印 [corowork] Stop coroutine ONE
>
> -> 至此两个任务全部完成，事件循环停止
>
> -> 打印两个任务的 result
>
> -> 打印程序运行时间
>
> -> 程序全部结束

**需要额外说明的几点：**

1、多数情况下无需调用 task 的 add_done_callback 方法，可以直接把回调函数中的代码写入 await 语句后面，协程是可以暂停和恢复的

2、多数情况下同样无需调用 task 的 result 方法获取协程函数的 return 值，因为事件循环的 run_until_complete 方法的返回值就是协程函数的 return 值。修改上文 # 6 、7 的代码如下：

```python
    ...:     result = loop.run_until_complete(gather)
    ...:     print(result)
```

再次运行结果为：

```python
In [73]: four()
[corowork] Start coroutine ONE
[corowork] Start coroutine TWO
[corowork] Stop coroutine TWO
[corowork] Stop coroutine ONE
['Coroutine ONE OK', 'Coroutine TWO OK']  # 变量 result 的值
运行耗时：3.0045
```

3、事件循环有一个 stop 方法用来停止循环和一个 close 方法用来关闭循环。以上示例中都没有调用 loop.close 方法，似乎并没有什么问题。所以到底要不要调用 loop.close 呢？简单来说，loop 只要不关闭，就还可以再次运行 run_until_complete 方法，关闭后则不可运行。有人会建议调用 loop.close，彻底清理 loop 对象防止误用，其实多数情况下根本没有这个必要。

4、asyncio 模块提供了 asyncio.gather 和 asyncio.wait 两个任务收集方法，它们的作用相同，都是将协程任务按顺序排定，再将返回值作为参数加入到事件循环中。前者在上文已经用到，后者与前者的区别是它可以获取任务的执行状态（PENING & FINISHED），当有一些特别的需求例如在某些情况下取消任务，可以使用 asyncio.wait 方法。



#### 协程锁

按照字面意思来看，asyncio.lock 应该叫做异步 IO 锁，之所以叫协程锁，是因为它通常使用在子协程中，其作用是将协程内部的一段代码锁住，直到这段代码运行完毕解锁。协程锁的固定用法是使用 async with 创建协程锁的上下文环境，将代码块写入其中。

举例说明，将以下代码写入 async_lock.py 文件：

```python
import asyncio

l = []
lock = asyncio.Lock()   # 协程锁

async def work(name):
    print('lalalalalalalala')     # 打印此信息是为了测试协程锁的控制范围
    # 这里加个锁，第一次调用该协程，运行到这个语句块，上锁
    # 当语句块结束后解锁，开锁前该语句块不可被运行第二次
    # 如果上锁后有其它任务调用了这个协程函数，运行到这步会被阻塞，直至解锁
    # with 是普通上下文管理器关键字，async with 是异步上下文管理器关键字
    # 能够使用 with 关键字的对象须有 __enter__ 和 __exit__ 方法
    # 能够使用 async with 关键字的对象须有 __aenter__ 和 __aexit__ 方法
    # async with 会自动运行 lock 的 __aenter__ 方法，该方法会调用 acquire 方法上锁
    # 在语句块结束时自动运行 __aexit__ 方法，该方法会调用 release 方法解锁
    # 这和 with 一样，都是简化 try ... finally 语句
    async with lock:
        print('{} start'.format(name))  # 头一次运行该协程时打印
        if 'x' in l:                    # 如果判断成功
            return name                 # 直接返回结束协程，不再向下执行
        await asyncio.sleep(0); print('----------')  # 阻塞 0 秒，切换协程
        l.append('x')
        print('{} end'.format(name))
        return name

async def one():
    name = await work('one')
    print('{} ok'.format(name))

async def two():
    name = await work('two')
    print('{} ok'.format(name))

def main():
    loop = asyncio.get_event_loop()
    tasks = asyncio.wait([one(), two()])
    loop.run_until_complete(tasks)

if __name__ == '__main__':
    main()
```

运行程序如下：

```python
$ python3 async_lock.py
lalalalalalalala
one start
lalalalalalalala
----------
one end
one ok
two start
two ok
```



### asyncio与gevent比较

> **Python中asyncio与gevent有什么区别?**
>
> asycio 需要自己在代码中让出CPU，控制权在自己手上
>
> gevent 用会替换标准库，你以为调用的是标准库的方法实际已经被替换成gevent自己的实现，遇到阻塞调用，gevent会自动让出CPU
>
> 像不像手动挡和自动挡的区别·····
>
> gevent是第三方库，通过greenlet实现协程，其基本思路是：
>
> 当一个greenlet遇到IO操作时，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。
>
> asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持，不需要第三方的支持，
>
> [asyncio的编程模型就是一个消息循环](https://www.zhihu.com/question/352297946/answer/872808274)。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。很多异步io操作这两个库都可以用，只是他们在不同场景下的效率和易用性可能有区别，当然这个得进行深入的测试和研究，单就现在普通的场景来说，区别并不大。
>
> gevent 是补丁，asyncio 是 python 3 原生；都能做到 异步 IO。如果现在写异步IO程序，应该用 asyncio。
>
> gevent 需要 patch，个人感觉不洁癖
>
> 比如有些时候不需要patch，或者自己实现的东西和patch冲突就麻烦了
>
> asyncio 系统自带，官方无忧
>
> python 3.5即可，3.7更多改进
>
> 前期：async await 一入门思维有点绕，gevent程序员一开始比较习惯；
>
> 后期：由于 async 和 await 关键字，asyncio 才是所见即所得！gevent入口去掉第一个spawn就是普通函数差不多了。
>
> 处理blocking，asyncio 是 run_in_executor 好用，gevent 是 ThreadPool，不好用。
>
> 警告或错误提示，asyncio提前到编译阶段，gevent只能运行阶段
>
> 启动：asyncio提供run_until_complete，gevent 是 join（spawn）；
>
> 同时启动多个：asyncio 用 asyncio.wait 包装 或 gather，gevent 是 joinall
>
> 未来：官方既然出了 asyncio，感觉gevent 将会过时。



# 相关疑问

## 多线程存在意义

> [多线程存在意义](https://www.zhihu.com/question/440212832)



